{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from spacy import displacy\n",
    "import networkx as nx\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords= stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get sentences and relations dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentences_and_relations(file):\n",
    "    '''\n",
    "    read the input file line by line and extract sentences and relations from it. \n",
    "    '''\n",
    "    sentences=[]\n",
    "    relations=[]\n",
    "\n",
    "    with open(file) as f:\n",
    "        i=1\n",
    "        for line in f:\n",
    "            # store sentence from line 1\n",
    "            if i==1:\n",
    "                sen=line.split('\"')[1]\n",
    "                sentences.append(sen)\n",
    "\n",
    "            # store relation from line 2\n",
    "            elif i==2:\n",
    "                # remove extra white spaces at the end\n",
    "                relation= line.strip()\n",
    "                relations.append(relation)\n",
    "                \n",
    "            elif i%4==0:\n",
    "                i=0\n",
    "\n",
    "            i+=1\n",
    "    return sentences, relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file= \"train.txt\"\n",
    "test_file= \"test.txt\"\n",
    "train_sent, train_rel= extract_sentences_and_relations(train_file)\n",
    "test_sent, test_rel= extract_sentences_and_relations(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr= \"semeval_train.txt\"\n",
    "te= \"semeval_test.txt\"\n",
    "tr_sen, tr_rel= extract_sentences_and_relations(tr)\n",
    "te_sen, te_rel= extract_sentences_and_relations(te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Component-Whole(e2,e1)'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_rel[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2717"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(te_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = {'Sentences': train_sent, 'Relations': train_rel}\n",
    "test = {'Sentences': test_sent, 'Relations': test_rel}\n",
    "train_df= pd.DataFrame(train, columns=['Sentences', 'Relations'])\n",
    "test_df= pd.DataFrame(test, columns=['Sentences', 'Relations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17641, 2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Relations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;e1&gt; Thom Yorke &lt;/e1&gt; of &lt;e2&gt; Radiohead &lt;/e2&gt;...</td>\n",
       "      <td>per:employee_of(e1,e2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;e1&gt; Leland High School &lt;/e1&gt; is a public hig...</td>\n",
       "      <td>org:city_of_headquarters(e1,e2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The 2008 Ohio Bobcats football team represent...</td>\n",
       "      <td>org:members(e2,e1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;e1&gt; Holy Cross High School &lt;/e1&gt; is a Cathol...</td>\n",
       "      <td>org:founded_by(e1,e2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hastings was unable to confirm news reports t...</td>\n",
       "      <td>per:employee_of(e2,e1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentences  \\\n",
       "0   <e1> Thom Yorke </e1> of <e2> Radiohead </e2>...   \n",
       "1   <e1> Leland High School </e1> is a public hig...   \n",
       "2   The 2008 Ohio Bobcats football team represent...   \n",
       "3   <e1> Holy Cross High School </e1> is a Cathol...   \n",
       "4   Hastings was unable to confirm news reports t...   \n",
       "\n",
       "                         Relations  \n",
       "0           per:employee_of(e1,e2)  \n",
       "1  org:city_of_headquarters(e1,e2)  \n",
       "2               org:members(e2,e1)  \n",
       "3            org:founded_by(e1,e2)  \n",
       "4           per:employee_of(e2,e1)  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df.Relations.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3405, 2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Relations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>After returning to the U.K. she attended the ...</td>\n",
       "      <td>org:stateorprovince_of_headquarters(e2,e1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Supported by their own buying staff &lt;e1&gt; Mars...</td>\n",
       "      <td>org:stateorprovince_of_headquarters(e1,e2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The California Department of Alcohol and Drug...</td>\n",
       "      <td>org:stateorprovince_of_headquarters(e2,e1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>But but &lt;e1&gt; Aetna &lt;/e1&gt; 's headquarters are ...</td>\n",
       "      <td>org:stateorprovince_of_headquarters(e1,e2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;e1&gt; Singapore Airlines &lt;/e1&gt; ( &lt;e2&gt; SIA &lt;/e2...</td>\n",
       "      <td>org:alternate_names(e1,e2)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentences  \\\n",
       "0   After returning to the U.K. she attended the ...   \n",
       "1   Supported by their own buying staff <e1> Mars...   \n",
       "2   The California Department of Alcohol and Drug...   \n",
       "3   But but <e1> Aetna </e1> 's headquarters are ...   \n",
       "4   <e1> Singapore Airlines </e1> ( <e2> SIA </e2...   \n",
       "\n",
       "                                    Relations  \n",
       "0  org:stateorprovince_of_headquarters(e2,e1)  \n",
       "1  org:stateorprovince_of_headquarters(e1,e2)  \n",
       "2  org:stateorprovince_of_headquarters(e2,e1)  \n",
       "3  org:stateorprovince_of_headquarters(e1,e2)  \n",
       "4                  org:alternate_names(e1,e2)  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df.Relations.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract e1, e2, and its position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_index(sen):\n",
    "    sen_list= sen.split()\n",
    "\n",
    "    for i, word in enumerate(sen_list):\n",
    "        if word=='<e1>':\n",
    "            start1=i\n",
    "\n",
    "        elif word=='</e1>':\n",
    "            end1=i\n",
    "\n",
    "        if word=='<e2>':\n",
    "            start2=i\n",
    "\n",
    "        elif word=='</e2>':\n",
    "            end2=i\n",
    "            \n",
    "    # get e1 and e2\n",
    "    e1= \" \".join(sen_list[start1+1 : end1])\n",
    "    e2= \" \".join(sen_list[start2+1 : end2])\n",
    "    \n",
    "    return e1, e2, [start1, end1, start2, end2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[['e1', 'e2', 'position']]= train_df.Sentences.apply(lambda sen: get_entity_index(sen)).apply(pd.Series)\n",
    "test_df[['e1', 'e2', 'position']]= test_df.Sentences.apply(lambda sen: get_entity_index(sen)).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Relations</th>\n",
       "      <th>e1</th>\n",
       "      <th>e2</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;e1&gt; Thom Yorke &lt;/e1&gt; of &lt;e2&gt; Radiohead &lt;/e2&gt;...</td>\n",
       "      <td>per:employee_of(e1,e2)</td>\n",
       "      <td>Thom Yorke</td>\n",
       "      <td>Radiohead</td>\n",
       "      <td>[0, 3, 5, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;e1&gt; Leland High School &lt;/e1&gt; is a public hig...</td>\n",
       "      <td>org:city_of_headquarters(e1,e2)</td>\n",
       "      <td>Leland High School</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>[0, 4, 16, 19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The 2008 Ohio Bobcats football team represent...</td>\n",
       "      <td>org:members(e2,e1)</td>\n",
       "      <td>Ohio University</td>\n",
       "      <td>NCAA</td>\n",
       "      <td>[7, 10, 14, 16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;e1&gt; Holy Cross High School &lt;/e1&gt; is a Cathol...</td>\n",
       "      <td>org:founded_by(e1,e2)</td>\n",
       "      <td>Holy Cross High School</td>\n",
       "      <td>Congregation of Holy Cross</td>\n",
       "      <td>[0, 5, 19, 24]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hastings was unable to confirm news reports t...</td>\n",
       "      <td>per:employee_of(e2,e1)</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>Bill Gwatney</td>\n",
       "      <td>[13, 15, 18, 21]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentences  \\\n",
       "0   <e1> Thom Yorke </e1> of <e2> Radiohead </e2>...   \n",
       "1   <e1> Leland High School </e1> is a public hig...   \n",
       "2   The 2008 Ohio Bobcats football team represent...   \n",
       "3   <e1> Holy Cross High School </e1> is a Cathol...   \n",
       "4   Hastings was unable to confirm news reports t...   \n",
       "\n",
       "                         Relations                      e1  \\\n",
       "0           per:employee_of(e1,e2)              Thom Yorke   \n",
       "1  org:city_of_headquarters(e1,e2)      Leland High School   \n",
       "2               org:members(e2,e1)         Ohio University   \n",
       "3            org:founded_by(e1,e2)  Holy Cross High School   \n",
       "4           per:employee_of(e2,e1)              Democratic   \n",
       "\n",
       "                           e2          position  \n",
       "0                   Radiohead      [0, 3, 5, 7]  \n",
       "1                    San Jose    [0, 4, 16, 19]  \n",
       "2                        NCAA   [7, 10, 14, 16]  \n",
       "3  Congregation of Holy Cross    [0, 5, 19, 24]  \n",
       "4                Bill Gwatney  [13, 15, 18, 21]  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove missing entity sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace empty e1 and e2 with na and then dropna \n",
    "train_df.replace('', np.nan, inplace=True)\n",
    "train_df.dropna(inplace=True)\n",
    "\n",
    "test_df.replace('', np.nan, inplace=True)\n",
    "test_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17521, 5)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3379, 5)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train.csv', index=False)\n",
    "test_df.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract nlp features from sentence, pos, enr, e1, e2, root, words in between "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sen_without_entity(sen):\n",
    "    sen_list= sen.split()\n",
    "    sen_without_entity= \" \".join([token for token in sen_list if token not in {'<e1>','</e1>', '<e2>', '</e2>'}]) \n",
    "    return sen_without_entity\n",
    "\n",
    "def get_pos(sen_without_entity):\n",
    "    sen_pos = [token.pos_ for token in nlp(sen_without_entity)]\n",
    "    return sen_pos\n",
    "\n",
    "def get_root(entity):\n",
    "    # create a span object that has property .root\n",
    "    doc = nlp(entity)\n",
    "    sen= list(doc.sents)[0]\n",
    "    return str(sen.root)\n",
    "\n",
    "def get_enr(entity):\n",
    "    for ent in nlp(entity).ents:\n",
    "        return str(ent.label_)\n",
    "\n",
    "def shortest_dep_path(sen, root_e1, root_e2):\n",
    "    doc = nlp(sen)\n",
    "    \n",
    "    #print dependency tree \n",
    "    #displacy.render(doc,jupyter=True)\n",
    "\n",
    "    # Load spacy's dependency tree into a networkx graph\n",
    "    edges = []\n",
    "    for token in doc:\n",
    "        for child in token.children:\n",
    "            edges.append(('{0}'.format(token.lower_),\n",
    "                          '{0}'.format(child.lower_)))\n",
    "            \n",
    "    graph = nx.Graph(edges)\n",
    "    entity1 = root_e1.lower()\n",
    "    entity2 = root_e2.lower()\n",
    "    \n",
    "    try:\n",
    "        out = str(\" \".join(nx.shortest_path(graph, source=entity1, target=entity2)[1:-1]))\n",
    "        \n",
    "    except (nx.NetworkXNoPath,  nx.NodeNotFound) as e:\n",
    "        out= None\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(df):\n",
    "    df['sen_without_entity']= df.Sentences.apply(get_sen_without_entity)\n",
    "    df['sen_pos']= df.sen_without_entity.apply(get_pos)\n",
    "    df['pos_e1']= df.apply(lambda row: str(row.sen_pos[row.position[0]]), axis=1)\n",
    "    df['pos_e2']= df.apply(lambda row: str(row.sen_pos[row.position[2]-2]), axis=1)\n",
    "    df['enr_e1']= df.e1.apply(get_enr)\n",
    "    df['enr_e2']= df.e2.apply(get_enr)\n",
    "    df['root_e1']= df.e1.apply(get_root)\n",
    "    df['root_e2']= df.e2.apply(get_root)\n",
    "    df['shortest_dep_path'] = df.apply(lambda row: shortest_dep_path(row.sen_without_entity, row.root_e1, row.root_e2), axis=1)\n",
    "    df['shortest_dep_path'] = df.apply(lambda row: shortest_dep_path(row.sen_without_entity, row.root_e1, row.root_e2), axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df= extract(train_df)\n",
    "test_df= extract(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing shortest dep path rows\n",
    "train_df.dropna(subset=['shortest_dep_path'], inplace= True)\n",
    "test_df.dropna(subset=['shortest_dep_path'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Relations</th>\n",
       "      <th>e1</th>\n",
       "      <th>e2</th>\n",
       "      <th>position</th>\n",
       "      <th>sen_without_entity</th>\n",
       "      <th>sen_pos</th>\n",
       "      <th>pos_e1</th>\n",
       "      <th>pos_e2</th>\n",
       "      <th>enr_e1</th>\n",
       "      <th>enr_e2</th>\n",
       "      <th>root_e1</th>\n",
       "      <th>root_e2</th>\n",
       "      <th>shortest_dep_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;e1&gt; Thom Yorke &lt;/e1&gt; of &lt;e2&gt; Radiohead &lt;/e2&gt;...</td>\n",
       "      <td>per:employee_of(e1,e2)</td>\n",
       "      <td>Thom Yorke</td>\n",
       "      <td>Radiohead</td>\n",
       "      <td>[0, 3, 5, 7]</td>\n",
       "      <td>Thom Yorke of Radiohead has included the + for...</td>\n",
       "      <td>[PROPN, PROPN, ADP, PROPN, AUX, VERB, DET, NUM...</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Yorke</td>\n",
       "      <td>Radiohead</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;e1&gt; Leland High School &lt;/e1&gt; is a public hig...</td>\n",
       "      <td>org:city_of_headquarters(e1,e2)</td>\n",
       "      <td>Leland High School</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>[0, 4, 16, 19]</td>\n",
       "      <td>Leland High School is a public high school loc...</td>\n",
       "      <td>[PROPN, PROPN, PROPN, AUX, DET, ADJ, ADJ, NOUN...</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ORG</td>\n",
       "      <td>GPE</td>\n",
       "      <td>School</td>\n",
       "      <td>Jose</td>\n",
       "      <td>district</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The 2008 Ohio Bobcats football team represent...</td>\n",
       "      <td>org:members(e2,e1)</td>\n",
       "      <td>Ohio University</td>\n",
       "      <td>NCAA</td>\n",
       "      <td>[7, 10, 14, 16]</td>\n",
       "      <td>The 2008 Ohio Bobcats football team represente...</td>\n",
       "      <td>[DET, NUM, PROPN, PROPN, NOUN, NOUN, VERB, PRO...</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ORG</td>\n",
       "      <td>ORG</td>\n",
       "      <td>University</td>\n",
       "      <td>NCAA</td>\n",
       "      <td>represented team the division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;e1&gt; Holy Cross High School &lt;/e1&gt; is a Cathol...</td>\n",
       "      <td>org:founded_by(e1,e2)</td>\n",
       "      <td>Holy Cross High School</td>\n",
       "      <td>Congregation of Holy Cross</td>\n",
       "      <td>[0, 5, 19, 24]</td>\n",
       "      <td>Holy Cross High School is a Catholic secondary...</td>\n",
       "      <td>[PROPN, PROPN, PROPN, PROPN, AUX, DET, ADJ, AD...</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ORG</td>\n",
       "      <td>None</td>\n",
       "      <td>School</td>\n",
       "      <td>Congregation</td>\n",
       "      <td>founded by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hastings was unable to confirm news reports t...</td>\n",
       "      <td>per:employee_of(e2,e1)</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>Bill Gwatney</td>\n",
       "      <td>[13, 15, 18, 21]</td>\n",
       "      <td>Hastings was unable to confirm news reports th...</td>\n",
       "      <td>[PROPN, AUX, ADJ, PART, VERB, NOUN, VERB, SCON...</td>\n",
       "      <td>PART</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>None</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>Gwatney</td>\n",
       "      <td>party chairman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentences  \\\n",
       "0   <e1> Thom Yorke </e1> of <e2> Radiohead </e2>...   \n",
       "1   <e1> Leland High School </e1> is a public hig...   \n",
       "2   The 2008 Ohio Bobcats football team represent...   \n",
       "3   <e1> Holy Cross High School </e1> is a Cathol...   \n",
       "4   Hastings was unable to confirm news reports t...   \n",
       "\n",
       "                         Relations                      e1  \\\n",
       "0           per:employee_of(e1,e2)              Thom Yorke   \n",
       "1  org:city_of_headquarters(e1,e2)      Leland High School   \n",
       "2               org:members(e2,e1)         Ohio University   \n",
       "3            org:founded_by(e1,e2)  Holy Cross High School   \n",
       "4           per:employee_of(e2,e1)              Democratic   \n",
       "\n",
       "                           e2          position  \\\n",
       "0                   Radiohead      [0, 3, 5, 7]   \n",
       "1                    San Jose    [0, 4, 16, 19]   \n",
       "2                        NCAA   [7, 10, 14, 16]   \n",
       "3  Congregation of Holy Cross    [0, 5, 19, 24]   \n",
       "4                Bill Gwatney  [13, 15, 18, 21]   \n",
       "\n",
       "                                  sen_without_entity  \\\n",
       "0  Thom Yorke of Radiohead has included the + for...   \n",
       "1  Leland High School is a public high school loc...   \n",
       "2  The 2008 Ohio Bobcats football team represente...   \n",
       "3  Holy Cross High School is a Catholic secondary...   \n",
       "4  Hastings was unable to confirm news reports th...   \n",
       "\n",
       "                                             sen_pos pos_e1 pos_e2 enr_e1  \\\n",
       "0  [PROPN, PROPN, ADP, PROPN, AUX, VERB, DET, NUM...  PROPN  PROPN   None   \n",
       "1  [PROPN, PROPN, PROPN, AUX, DET, ADJ, ADJ, NOUN...  PROPN  PROPN    ORG   \n",
       "2  [DET, NUM, PROPN, PROPN, NOUN, NOUN, VERB, PRO...  PROPN  PROPN    ORG   \n",
       "3  [PROPN, PROPN, PROPN, PROPN, AUX, DET, ADJ, AD...  PROPN  PROPN    ORG   \n",
       "4  [PROPN, AUX, ADJ, PART, VERB, NOUN, VERB, SCON...   PART   NOUN   None   \n",
       "\n",
       "   enr_e2     root_e1       root_e2              shortest_dep_path  \n",
       "0    None       Yorke     Radiohead                             of  \n",
       "1     GPE      School          Jose                       district  \n",
       "2     ORG  University          NCAA  represented team the division  \n",
       "3    None      School  Congregation                     founded by  \n",
       "4  PERSON  Democratic       Gwatney                 party chairman  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Relations</th>\n",
       "      <th>e1</th>\n",
       "      <th>e2</th>\n",
       "      <th>position</th>\n",
       "      <th>sen_without_entity</th>\n",
       "      <th>sen_pos</th>\n",
       "      <th>pos_e1</th>\n",
       "      <th>pos_e2</th>\n",
       "      <th>enr_e1</th>\n",
       "      <th>enr_e2</th>\n",
       "      <th>root_e1</th>\n",
       "      <th>root_e2</th>\n",
       "      <th>shortest_dep_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>After returning to the U.K. she attended the ...</td>\n",
       "      <td>org:stateorprovince_of_headquarters(e2,e1)</td>\n",
       "      <td>Isle of Wight</td>\n",
       "      <td>Ryde School with Upper Chine</td>\n",
       "      <td>[16, 20, 32, 38]</td>\n",
       "      <td>After returning to the U.K. she attended the i...</td>\n",
       "      <td>[ADP, VERB, ADP, DET, PROPN, PRON, VERB, DET, ...</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Isle</td>\n",
       "      <td>School</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Supported by their own buying staff &lt;e1&gt; Mars...</td>\n",
       "      <td>org:stateorprovince_of_headquarters(e1,e2)</td>\n",
       "      <td>Mars</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>[6, 8, 25, 27]</td>\n",
       "      <td>Supported by their own buying staff Mars purch...</td>\n",
       "      <td>[VERB, ADP, DET, ADJ, NOUN, NOUN, PROPN, NOUN,...</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>LOC</td>\n",
       "      <td>GPE</td>\n",
       "      <td>Mars</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>purchases produce seafood from growers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The California Department of Alcohol and Drug...</td>\n",
       "      <td>org:stateorprovince_of_headquarters(e2,e1)</td>\n",
       "      <td>California</td>\n",
       "      <td>substance abuse</td>\n",
       "      <td>[13, 15, 20, 23]</td>\n",
       "      <td>The California Department of Alcohol and Drug ...</td>\n",
       "      <td>[DET, PROPN, PROPN, ADP, PROPN, CCONJ, PROPN, ...</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>GPE</td>\n",
       "      <td>None</td>\n",
       "      <td>California</td>\n",
       "      <td>abuse</td>\n",
       "      <td>agency concerned with prevention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>But but &lt;e1&gt; Aetna &lt;/e1&gt; 's headquarters are ...</td>\n",
       "      <td>org:stateorprovince_of_headquarters(e1,e2)</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>[2, 4, 9, 11]</td>\n",
       "      <td>But but Aetna 's headquarters are in Connectic...</td>\n",
       "      <td>[CCONJ, CCONJ, PROPN, PART, NOUN, AUX, ADP, PR...</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ORG</td>\n",
       "      <td>GPE</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>headquarters are in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;e1&gt; Singapore Airlines &lt;/e1&gt; ( &lt;e2&gt; SIA &lt;/e2...</td>\n",
       "      <td>org:alternate_names(e1,e2)</td>\n",
       "      <td>Singapore Airlines</td>\n",
       "      <td>SIA</td>\n",
       "      <td>[0, 3, 5, 7]</td>\n",
       "      <td>Singapore Airlines ( SIA ) said Wednesday it w...</td>\n",
       "      <td>[PROPN, PROPN, PUNCT, PROPN, PUNCT, VERB, PROP...</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ORG</td>\n",
       "      <td>None</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>SIA</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentences  \\\n",
       "0   After returning to the U.K. she attended the ...   \n",
       "1   Supported by their own buying staff <e1> Mars...   \n",
       "2   The California Department of Alcohol and Drug...   \n",
       "3   But but <e1> Aetna </e1> 's headquarters are ...   \n",
       "4   <e1> Singapore Airlines </e1> ( <e2> SIA </e2...   \n",
       "\n",
       "                                    Relations                  e1  \\\n",
       "0  org:stateorprovince_of_headquarters(e2,e1)       Isle of Wight   \n",
       "1  org:stateorprovince_of_headquarters(e1,e2)                Mars   \n",
       "2  org:stateorprovince_of_headquarters(e2,e1)          California   \n",
       "3  org:stateorprovince_of_headquarters(e1,e2)               Aetna   \n",
       "4                  org:alternate_names(e1,e2)  Singapore Airlines   \n",
       "\n",
       "                             e2          position  \\\n",
       "0  Ryde School with Upper Chine  [16, 20, 32, 38]   \n",
       "1                      Maryland    [6, 8, 25, 27]   \n",
       "2               substance abuse  [13, 15, 20, 23]   \n",
       "3                   Connecticut     [2, 4, 9, 11]   \n",
       "4                           SIA      [0, 3, 5, 7]   \n",
       "\n",
       "                                  sen_without_entity  \\\n",
       "0  After returning to the U.K. she attended the i...   \n",
       "1  Supported by their own buying staff Mars purch...   \n",
       "2  The California Department of Alcohol and Drug ...   \n",
       "3  But but Aetna 's headquarters are in Connectic...   \n",
       "4  Singapore Airlines ( SIA ) said Wednesday it w...   \n",
       "\n",
       "                                             sen_pos pos_e1 pos_e2 enr_e1  \\\n",
       "0  [ADP, VERB, ADP, DET, PROPN, PRON, VERB, DET, ...  PROPN  PROPN   None   \n",
       "1  [VERB, ADP, DET, ADJ, NOUN, NOUN, PROPN, NOUN,...  PROPN  PROPN    LOC   \n",
       "2  [DET, PROPN, PROPN, ADP, PROPN, CCONJ, PROPN, ...  PROPN   NOUN    GPE   \n",
       "3  [CCONJ, CCONJ, PROPN, PART, NOUN, AUX, ADP, PR...  PROPN  PROPN    ORG   \n",
       "4  [PROPN, PROPN, PUNCT, PROPN, PUNCT, VERB, PROP...  PROPN  PROPN    ORG   \n",
       "\n",
       "  enr_e2     root_e1      root_e2                       shortest_dep_path  \n",
       "0   None        Isle       School                                     the  \n",
       "1    GPE        Mars     Maryland  purchases produce seafood from growers  \n",
       "2   None  California        abuse        agency concerned with prevention  \n",
       "3    GPE       Aetna  Connecticut                     headquarters are in  \n",
       "4   None    Airlines          SIA                                          "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17255, 14)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3331, 14)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train.csv', index=False)\n",
    "test_df.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df= pd.read_csv('train.csv')\n",
    "test_df= pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get words in between in lemma form and after removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_in_between(sen):\n",
    "    '''\n",
    "    get the words in between entities which are not stop words\n",
    "    '''\n",
    "    words= sen.sen_without_entity.split()\n",
    "    words_in_between= words[sen.position[1]-1: sen.position[2]-2]\n",
    "    return \" \".join([word for word in words_in_between if word not in stopwords])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['words_in_between']= train_df.apply(get_words_in_between, axis=1)\n",
    "test_df['words_in_between']= test_df.apply(get_words_in_between, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train.csv', index=False)\n",
    "test_df.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sen_without_entity(sen):\n",
    "    '''\n",
    "    remove entity tags from the sentence and get its lemma form, return string\n",
    "    '''\n",
    "    sen_list= sen.split()\n",
    "    sen_without_entity= \" \".join([token for token in sen_list if token not in {'<e1>','</e1>', '<e2>', '</e2>'}]) \n",
    "    words=[str(token.lemma_) for token in nlp(sen_without_entity)]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['sen_without_entity']= train_df.Sentences.apply(get_sen_without_entity)\n",
    "test_df['sen_without_entity']= test_df.Sentences.apply(get_sen_without_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Relations</th>\n",
       "      <th>e1</th>\n",
       "      <th>e2</th>\n",
       "      <th>position</th>\n",
       "      <th>sen_without_entity</th>\n",
       "      <th>sen_pos</th>\n",
       "      <th>pos_e1</th>\n",
       "      <th>pos_e2</th>\n",
       "      <th>enr_e1</th>\n",
       "      <th>enr_e2</th>\n",
       "      <th>root_e1</th>\n",
       "      <th>root_e2</th>\n",
       "      <th>shortest_dep_path</th>\n",
       "      <th>words_in_between</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;e1&gt; Thom Yorke &lt;/e1&gt; of &lt;e2&gt; Radiohead &lt;/e2&gt;...</td>\n",
       "      <td>per:employee_of(e1,e2)</td>\n",
       "      <td>Thom Yorke</td>\n",
       "      <td>Radiohead</td>\n",
       "      <td>[0, 3, 5, 7]</td>\n",
       "      <td>Thom Yorke of Radiohead have include the + for...</td>\n",
       "      <td>['PROPN', 'PROPN', 'ADP', 'PROPN', 'AUX', 'VER...</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yorke</td>\n",
       "      <td>Radiohead</td>\n",
       "      <td>of</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;e1&gt; Leland High School &lt;/e1&gt; is a public hig...</td>\n",
       "      <td>org:city_of_headquarters(e1,e2)</td>\n",
       "      <td>Leland High School</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>[0, 4, 16, 19]</td>\n",
       "      <td>Leland High School be a public high school loc...</td>\n",
       "      <td>['PROPN', 'PROPN', 'PROPN', 'AUX', 'DET', 'ADJ...</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ORG</td>\n",
       "      <td>GPE</td>\n",
       "      <td>School</td>\n",
       "      <td>Jose</td>\n",
       "      <td>district</td>\n",
       "      <td>[public, high, school, locate, Almaden, Valley]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The 2008 Ohio Bobcats football team represent...</td>\n",
       "      <td>org:members(e2,e1)</td>\n",
       "      <td>Ohio University</td>\n",
       "      <td>NCAA</td>\n",
       "      <td>[7, 10, 14, 16]</td>\n",
       "      <td>the 2008 Ohio Bobcats football team represent ...</td>\n",
       "      <td>['DET', 'NUM', 'PROPN', 'PROPN', 'NOUN', 'NOUN...</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ORG</td>\n",
       "      <td>ORG</td>\n",
       "      <td>University</td>\n",
       "      <td>NCAA</td>\n",
       "      <td>represented team the division</td>\n",
       "      <td>[2008]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;e1&gt; Holy Cross High School &lt;/e1&gt; is a Cathol...</td>\n",
       "      <td>org:founded_by(e1,e2)</td>\n",
       "      <td>Holy Cross High School</td>\n",
       "      <td>Congregation of Holy Cross</td>\n",
       "      <td>[0, 5, 19, 24]</td>\n",
       "      <td>Holy Cross High School be a catholic secondary...</td>\n",
       "      <td>['PROPN', 'PROPN', 'PROPN', 'PROPN', 'AUX', 'D...</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ORG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>School</td>\n",
       "      <td>Congregation</td>\n",
       "      <td>founded by</td>\n",
       "      <td>[catholic, secondary, school, found, Waterbury...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hastings was unable to confirm news reports t...</td>\n",
       "      <td>per:employee_of(e2,e1)</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>Bill Gwatney</td>\n",
       "      <td>[13, 15, 18, 21]</td>\n",
       "      <td>Hastings be unable to confirm news report that...</td>\n",
       "      <td>['PROPN', 'AUX', 'ADJ', 'PART', 'VERB', 'NOUN'...</td>\n",
       "      <td>PART</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>Gwatney</td>\n",
       "      <td>party chairman</td>\n",
       "      <td>[Democratic, Party]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentences  \\\n",
       "0   <e1> Thom Yorke </e1> of <e2> Radiohead </e2>...   \n",
       "1   <e1> Leland High School </e1> is a public hig...   \n",
       "2   The 2008 Ohio Bobcats football team represent...   \n",
       "3   <e1> Holy Cross High School </e1> is a Cathol...   \n",
       "4   Hastings was unable to confirm news reports t...   \n",
       "\n",
       "                         Relations                      e1  \\\n",
       "0           per:employee_of(e1,e2)              Thom Yorke   \n",
       "1  org:city_of_headquarters(e1,e2)      Leland High School   \n",
       "2               org:members(e2,e1)         Ohio University   \n",
       "3            org:founded_by(e1,e2)  Holy Cross High School   \n",
       "4           per:employee_of(e2,e1)              Democratic   \n",
       "\n",
       "                           e2          position  \\\n",
       "0                   Radiohead      [0, 3, 5, 7]   \n",
       "1                    San Jose    [0, 4, 16, 19]   \n",
       "2                        NCAA   [7, 10, 14, 16]   \n",
       "3  Congregation of Holy Cross    [0, 5, 19, 24]   \n",
       "4                Bill Gwatney  [13, 15, 18, 21]   \n",
       "\n",
       "                                  sen_without_entity  \\\n",
       "0  Thom Yorke of Radiohead have include the + for...   \n",
       "1  Leland High School be a public high school loc...   \n",
       "2  the 2008 Ohio Bobcats football team represent ...   \n",
       "3  Holy Cross High School be a catholic secondary...   \n",
       "4  Hastings be unable to confirm news report that...   \n",
       "\n",
       "                                             sen_pos pos_e1 pos_e2 enr_e1  \\\n",
       "0  ['PROPN', 'PROPN', 'ADP', 'PROPN', 'AUX', 'VER...  PROPN  PROPN    NaN   \n",
       "1  ['PROPN', 'PROPN', 'PROPN', 'AUX', 'DET', 'ADJ...  PROPN  PROPN    ORG   \n",
       "2  ['DET', 'NUM', 'PROPN', 'PROPN', 'NOUN', 'NOUN...  PROPN  PROPN    ORG   \n",
       "3  ['PROPN', 'PROPN', 'PROPN', 'PROPN', 'AUX', 'D...  PROPN  PROPN    ORG   \n",
       "4  ['PROPN', 'AUX', 'ADJ', 'PART', 'VERB', 'NOUN'...   PART   NOUN    NaN   \n",
       "\n",
       "   enr_e2     root_e1       root_e2              shortest_dep_path  \\\n",
       "0     NaN       Yorke     Radiohead                             of   \n",
       "1     GPE      School          Jose                       district   \n",
       "2     ORG  University          NCAA  represented team the division   \n",
       "3     NaN      School  Congregation                     founded by   \n",
       "4  PERSON  Democratic       Gwatney                 party chairman   \n",
       "\n",
       "                                    words_in_between  \n",
       "0                                                 []  \n",
       "1    [public, high, school, locate, Almaden, Valley]  \n",
       "2                                             [2008]  \n",
       "3  [catholic, secondary, school, found, Waterbury...  \n",
       "4                                [Democratic, Party]  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17255, 15) (3331, 15)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train.csv', index=False)\n",
    "test_df.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
